# src/main_analysis.py
import json
import logging
from config.config_loader import ConfigLoader
from project_analyzer import ProjectAnalyzer
from vector.vector_store import VectorStore
from agents.agent_manager import AgentManager
from models.analysis_context import AnalysisContext

# Configuration du logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def main():
    """Point d'entr√©e principal pour l'analyse et la g√©n√©ration de code"""
    try:
        # Chargement configuration
        logger.info("‚öôÔ∏è  Chargement de la configuration...")
        config_loader = ConfigLoader()
        config = config_loader.config

        # √âtape 1: Analyse de la structure du projet
        logger.info("üîç Analyse de la structure du projet...")
        project_analyzer = ProjectAnalyzer(config)
        project_structure = project_analyzer.analyze_project_structure()

        # √âtape 2: R√©cup√©ration des chunks vectoris√©s
        logger.info("üìö R√©cup√©ration des chunks depuis la base vectorielle...")
        vector_store = VectorStore(config)
        chunks = vector_store.get_all_chunks(limit=2000)

        if not chunks:
            logger.error("‚ùå Aucun chunk trouv√© dans la base vectorielle")
            return

        logger.info(f"üìä Analyse bas√©e sur {len(chunks)} chunks et structure de projet")

        # √âtape 3: Pr√©parer le contexte d'analyse
        context = AnalysisContext(
            project_structure=project_structure,
            chunks=chunks,
            project_config=config.get('project', {})
        )

        # √âtape 4: Ex√©cution du pipeline d'agents d'analyse
        logger.info("ü§ñ Lancement des agents d'analyse...")
        agent_manager = AgentManager(config)
        analysis_results = agent_manager.run_analysis_pipeline(context,vector_store)

        # On peut ici envisager un pipeline de g√©n√©ration plus tard
        # generation_results = generation_agent.generate(context, analysis_results)

        # √âtape 5: Sauvegarde ou export des r√©sultats
        logger.info("üíæ Sauvegarde des r√©sultats...")
        vector_store.persist_index()  # sauvegarde de l'index et persistance
        with open('data.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, ensure_ascii=False, indent=4)

        # √âtape 6: R√©sum√©
        stats = {
            'total_chunks': len(chunks),
            'total_modules': len(project_structure.modules),
            'patterns_identified': project_structure.patterns_identified,
            'analysis_count': len(analysis_results),
        }
        logger.info(f"üìà R√©sum√© de l'analyse: {stats}")

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'analyse: {e}", exc_info=True)
        raise

if __name__ == "__main__":
    main()
