# src/main_analysis.py

import logging
from typing import List, Dict, Any

from parsers.utils.Util import infer_language_from_path, infer_category_from_type
from models.analysis_context import AnalysisContext
from models.code_chunk import CodeChunk
from models.project_structure import ProjectStructure

from agents.agent_manager import AgentManager
from config.config_loader import ConfigLoader
from main_doc import RuleGenerator
from project_analyzer import ProjectAnalyzer
from vector.vector_store import VectorStore, get_existing_chunks, get_all_chunks_direct

# Configuration du logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


def analyze_project_structure(config: Dict[str, Any]) -> Dict[str, Any]:
    """Analyse la structure du projet"""
    logger.info("üîç Analyse de la structure du projet...")
    project_analyzer = ProjectAnalyzer(config)
    return project_analyzer.analyze_project_structure()


def get_chunks_for_analysis(config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """R√©cup√®re les chunks pour l'analyse"""
    logger.info("üìö R√©cup√©ration des chunks depuis la base vectorielle...")

    vector_store = VectorStore(config)

    # M√©thode 1: R√©cup√©ration directe (plus efficace)
    chunks = get_all_chunks_direct(vector_store, limit=2000)

    if not chunks:
        # M√©thode 2: Fallback avec recherche neutre
        logger.warning(
            "M√©thode directe √©chou√©e, utilisation de la m√©thode de recherche..."
        )
        chunks = get_existing_chunks(vector_store, config, limit=1000)

    # Filtrer et organiser les chunks par type pour l'analyse
    organized_chunks = organize_chunks_by_type(chunks)

    return organized_chunks


def organize_chunks_by_type(chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Organise les chunks par type pour une analyse plus efficace"""
    organized = []

    for chunk in chunks:
        metadata = chunk.get("metadata", {})
        chunk_type = metadata.get("chunk_type", "unknown")
        file_path = metadata.get("file_path", "")

        enhanced_chunk = {
            "content": chunk["content"],
            "type": chunk_type,
            "file_path": file_path,
            "filename": metadata.get("filename", ""),
            "language": infer_language_from_path(file_path),
            "category": infer_category_from_type(chunk_type, file_path),
        }
        organized.append(enhanced_chunk)

    return organized


def main():
    """Point d'entr√©e principal pour l'analyse r√©trospective"""
    try:
        # Chargement configuration
        logger.info("‚öôÔ∏è Chargement de la configuration...")
        config_loader = ConfigLoader()
        config = config_loader.config

        # √âtape 1: Analyse de la structure du projet
        raw_structure = analyze_project_structure(config)

        # √âtape 2: R√©cup√©ration des chunks existants
        raw_chunks = get_chunks_for_analysis(config)

        if not raw_chunks:
            logger.error("‚ùå Aucun chunk trouv√© dans la base vectorielle")
            return

        # √âtape 2b: Cr√©ation des objets CodeChunk
        chunks = [
            CodeChunk(
                content=c["content"],
                file_path=c["file_path"],
                filename=c["filename"],
                language=c["language"],
                category=c["category"],
                chunk_type=c["type"],
            )
            for c in raw_chunks
        ]

        # √âtape 3: Cr√©ation de l'objet AnalysisContext
        analysis_context = AnalysisContext(
            project_structure=ProjectStructure(**raw_structure),
            chunks=chunks,
            config=config,
        )

        logger.info(f"üìä Analyse bas√©e sur {len(chunks)} chunks et structure de projet")

        # √âtape 4: Ex√©cution du pipeline d'agents
        logger.info("ü§ñ Lancement des agents d'analyse...")
        agent_manager = AgentManager(config_loader)
        results = agent_manager.run_analysis_pipeline(analysis_context)

        # √âtape 5: G√©n√©ration de la documentation
        logger.info("üìù G√©n√©ration de la documentation...")
        rule_generator = RuleGenerator(config)
        documentation_path = rule_generator.generate_rules_documentation(results)

        logger.info(f"‚úÖ Analyse termin√©e! Documentation g√©n√©r√©e: {documentation_path}")

        # R√©sum√©
        stats = {
            "total_chunks_analyzed": len(chunks),
            "patterns_identified": len(raw_structure.get("patterns", {})),
            "documentation_path": documentation_path,
        }

        logger.info(f"üìà R√©sum√©: {stats}")

    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'analyse: {e}")
        raise


if __name__ == "__main__":
    main()
